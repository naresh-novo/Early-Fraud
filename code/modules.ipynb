{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ea0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import graphviz\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from datetime import timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score,roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import stats\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bb716dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alloy_persons_data_path = '../data/raw/apps_data.pkl'\n",
    "alloy_persons_data = pd.read_pickle(alloy_persons_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f91344af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_nulls(train, test=pd.DataFrame(), num_impute_type='median'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to find the nulls/NaNs and impute values with corresponding impute methods.\n",
    "    'train' is dataset is necessary parameter and 'test' dataset is optional parameter\n",
    "        Parameters:\n",
    "            train (dataframe): Dataframe dataset\n",
    "            test (dataframe): Dataframe dataset\n",
    "            num_impute (string): 'mean' or 'median' impute methiods for numerical columns\n",
    "            for categorical columns, 'mode' is used\n",
    "\n",
    "        Returns:\n",
    "            train (dataframe): Dataframe\n",
    "            test (dataframe): Dataframe\n",
    "    \"\"\"\n",
    "    train = train\n",
    "    test = test\n",
    "    num_impute_type = num_impute_type\n",
    "    \n",
    "    if train.shape[0] == 0 and train.shape[0] == 0:\n",
    "        print(\"Given train and test datasets are empty\")\n",
    "        return train, test\n",
    "    \n",
    "    elif train.shape[0] > 0:\n",
    "        \n",
    "        for col in train.columns:\n",
    "            if train[col].dtype.name in ['int64','float64','object','category']:\n",
    "                if train[col].dtype.name in ['int64','float64']:\n",
    "                    if num_impute_type == 'mean':\n",
    "                        impute_value = train[col].mean()\n",
    "                    else:\n",
    "                        impute_value = train[col].median()\n",
    "                else:\n",
    "                    impute_value = train[col].mode()[0]\n",
    "\n",
    "                idx = train.index[train[col].isnull()].tolist()\n",
    "                idx.extend(train.index[train[col].isna()].tolist())\n",
    "                idx.extend(train.index[train[col] == ''].tolist())\n",
    "                idx = list(set(idx))\n",
    "                tmp = train.filter(items=idx, axis=0)\n",
    "                tmp[col] = impute_value\n",
    "                train.update(tmp)\n",
    "\n",
    "                if test.shape[0] > 0 and set(train.columns)-set(test.columns) == set():\n",
    "                    idx = test.index[test[col].isnull()].tolist()\n",
    "                    idx.extend(test.index[test[col].isna()].tolist())\n",
    "                    idx.extend(test.index[test[col] == ''].tolist())\n",
    "                    idx = list(set(idx))\n",
    "                    tmp = test.filter(items=idx, axis=0)\n",
    "                    tmp[col] = impute_value\n",
    "                    test.update(tmp)\n",
    "    \n",
    "    if train.shape[0] > 0 and test.shape[0] > 0 and set(train.columns)-set(test.columns) == set():\n",
    "        return train, test\n",
    "    else:\n",
    "        return train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3498ad",
   "metadata": {},
   "source": [
    "There are id columns and also columns with more than 20 unique values will be ignored to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a2636fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_encoding(data=pd.DataFrame(), encode_columns=[], encode_type='onehot', max_unique_values=20):\n",
    "    \"\"\"\n",
    "    Function to encode the categorical variables.\n",
    "    'data' is necessary parameter and 'encode_columns' & 'encode_type' are optional parameters\n",
    "        Parameters:\n",
    "            data (dataframe): Dataframe dataset\n",
    "            encode_columns (list): List of columns that require encoding\n",
    "            encode_type (string): 'onehot' or 'label' encoding methiods\n",
    "\n",
    "        Returns:\n",
    "            data (dataframe): Transformed dataframe\n",
    "    \"\"\"\n",
    "    data = data\n",
    "    encode_columns = encode_columns\n",
    "    encode_type = encode_type\n",
    "    max_unique_values = max_unique_values\n",
    "\n",
    "    if data.shape[0] > 0:\n",
    "        if len(encode_columns) == 0:\n",
    "            cat_columns = [col for col in data.columns if data[col].dtype.name in ['object','category','bool']]\n",
    "        else:\n",
    "            cat_columns = encode_columns\n",
    "        \n",
    "        cat_columns = [col for col in cat_columns if data[col].agg(['nunique'])[0] <= max_unique_values]\n",
    "        rest_columns = list(set(data.columns)-set(cat_columns))\n",
    "\n",
    "        if encode_type == 'onehot':\n",
    "            cat_data = pd.get_dummies(data[cat_columns])\n",
    "            if len(rest_columns) > 0:\n",
    "                rest_data = data[rest_columns]\n",
    "                data = pd.concat([rest_data, cat_data], axis=1)\n",
    "            else:\n",
    "                data = cat_data\n",
    "        else:\n",
    "            data_tmp = pd.DataFrame(columns=cat_columns)\n",
    "            for col in cat_columns:\n",
    "                data_tmp[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "            if len(rest_columns) > 0:\n",
    "                rest_data = data[rest_columns]\n",
    "                data = pd.concat([rest_data, data_tmp], axis=1)\n",
    "            else:\n",
    "                data = data_tmp\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "9f265194",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = impute_nulls(train=alloy_persons_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "68834c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_columns = alloy_persons_data.columns\n",
    "data = feature_encoding(data=alloy_persons_data, encode_columns=[], max_unique_values=60, encode_type='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "ba5d369f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116433, 101)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d42890c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_models(x_train, y_train, params_lr={}, params_svc={'kernel':'linear'}, params_dtc={}, \n",
    "                          params_rfc={}, params_xgbc={}, models=[]):\n",
    "    \"\"\"\n",
    "    Function to train the linear, logistic, decision trees.\n",
    "    'train_data' is necessary parameter and remaining are optional parameters\n",
    "        Parameters:\n",
    "            x_train (dataframe): Dataframe dataset\n",
    "            y_train (dataframe): Dataframe dataset\n",
    "            params_lr (dict): logistic regression parameters\n",
    "            params_dtc (dict): decision tree parameters\n",
    "            params_svc (dict): SVC parameters\n",
    "            params_rfc (dict): random forest classifier parameters\n",
    "            params_xgbc (dict): xboost classifier parameters\n",
    "            models (list): ['lr','svc','dtc','rfc','xgbc']\n",
    "\n",
    "        Returns:\n",
    "            lr (object): trained model output\n",
    "            svc (object): trained model output\n",
    "            dtc (object): trained model output\n",
    "            rfc (object): trained model output\n",
    "            xgbc (object): trained model output\n",
    "    \"\"\"\n",
    "    params_lr = params_lr\n",
    "    params_svc = params_svc\n",
    "    params_dtc = params_dtc\n",
    "    params_rfc = params_rfc\n",
    "    params_xgbc = params_xgbc\n",
    "    models = models\n",
    "    \n",
    "    lr = ''\n",
    "    svc = ''\n",
    "    dtc = '' \n",
    "    rfc = '' \n",
    "    xgbc = ''\n",
    "    \n",
    "    if models == [] or 'lr' in models:\n",
    "        if params_lr == {}:\n",
    "            lr = LogisticRegression().fit(x_train, y_train)\n",
    "        else:\n",
    "            lr = LogisticRegression(params_lr).fit(x_train, y_train)\n",
    "    if models == [] or 'svc' in models:\n",
    "        if params_svc == {}:\n",
    "            svc = SVC().fit(x_train, y_train)\n",
    "        else:\n",
    "            svc = SVC(params_svc).fit(x_train, y_train)\n",
    "    if models == [] or 'dtc' in models:\n",
    "        if params_dtc == {}:\n",
    "            dtc = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "        else:\n",
    "            dtc = DecisionTreeClassifier(params_dtc).fit(x_train, y_train)\n",
    "    if models == [] or 'rfc' in models:\n",
    "        if params_rfc == {}:\n",
    "            rfc = RandomForestClassifier().fit(x_train, y_train)\n",
    "        else:\n",
    "            rfc = RandomForestClassifier(params_rfc).fit(x_train, y_train)\n",
    "    if models == [] or 'xgbc' in models:    \n",
    "        if params_xgbc == {}:\n",
    "            xgbc = XGBClassifier().fit(x_train, y_train)\n",
    "        else:\n",
    "            xgbc = XGBClassifier(params_xgbc).fit(x_train, y_train)\n",
    "    \n",
    "    return lr, svc, dtc, rfc, xgbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c1403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_treatment():\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd65a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ca847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
